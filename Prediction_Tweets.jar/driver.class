package Prediction;
	import java.io.IOException;
	import org.apache.hadoop.fs.Path;
	import org.apache.hadoop.io.IntWritable;
	import org.apache.hadoop.io.Text;
	import org.apache.hadoop.mapred.FileInputFormat;
	import org.apache.hadoop.mapred.FileOutputFormat;
	import org.apache.hadoop.mapred.JobClient;
	import org.apache.hadoop.mapred.JobConf;

	public class Tweet_Main1 {

	public static void main(String[] args) throws IOException {
	 if (args.length != 2) {
	   System.err.println("Usage: Prediction <input path> <output path>");
	   System.exit(-1);
	 }
	  JobConf conf = new JobConf(Tweet_Main1.class);
	 conf.setJobName("TWEETS PREDICTION");
	 FileInputFormat.addInputPath(conf, new Path(args[0]));
	 FileOutputFormat.setOutputPath(conf, new Path(args[1]));
	  conf.setMapperClass(Tweet_Map1.class);
	 conf.setCombinerClass(Tweet_Reduce1.class);
	 conf.setReducerClass(Tweet_Reduce1.class);
	  conf.setOutputKeyClass(Text.class);
	 conf.setOutputValueClass(IntWritable.class);
	 JobClient.runJob(conf);
	}
	}
